			+--------------------+
			|        CS 153      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Erin Mullally <emull005@ucr.edu> <860854551>
Candice Bentejac <cbent002@ucr.edu> <861246425>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

None.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread in thread.h:
int64_t wake_up_time;

If a thread is sleeping, this attribute indicates the moment (tick value)
when the thread can be waken up and put in the "Ready" list.


Added in timer.c:
static struct sleeping_threads;

List of the sleeping threads.

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

In timer_sleep(), we first compute the wake up time of the thread
and assign it to the attribute wake_up_time of the thread structure:
we do so by adding the parameter ticks to timer_ticks() (number of ticks
since the system has booted). We then disable the interrupts to add this 
thread to the sleeping_threads list, which is ordered (the first element 
will be the first to wake up). Once added to the list, the thread is 
blocked (its state changes from "Running" to "Waiting"). Once we are 
done with the list edition, the interrupts are re-enabled.

In timer_interrupt(), we iterate through the list, beginning with its
front element, and check whether it is time to wake up the thread or
not, using a comparator function (if the wake_up_time attribute of the
thread is smaller than timer_ticks(), then it can be woken up). If it
is time, the thread is removed from the list and unblocked (its state 
changes from "Wait" to "Ready") and we go to the next list element.
If it is not, then we break the iteration and simply exit the function. 

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

To minimize the time spent in the timer interrupt handler, we designed
our sleeping_threads list to be ordered: the first element will be the 
first to wake up, and so on. If at some point, a thread is not ready to
be woken up, it means that all the next list elements are not ready 
either. Instead of iterating through the whole list, we can directly
exit the function as soon as such an element is encountered.

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

In timer_sleep(), we disable the interrupts before accessing and
modifying our sleeping_threads list, which is the only global 
variable to be modified in the function. As the interrupts are 
disabled, there cannot be race conditions.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

In timer_sleep(), we disable the interrupts before accessing and 
moddifying our sleeping_threads list, which is the only global
variable to be modified in the function. As the interrupts are
disabled, there cannot be race conditions.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

The first design we considered implied an unordered list. It didn't need
a comparator function for insertions in the list, but it forced us to
iterate through the whole sleeping_threads list to be sure that every
thread would be woken up. The design we chose (a sorted list) allows us
to spend less time in the timer_interrupt(), since we don't have to iterate
through the whole list every single time.  

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Added to struct thread in thread.h:
 - int original_priority
   
Keeps record of the initial priority of a thread, in case another
thread would donate its own priority, to be able to restore it.

 - struct list priority_donors
   
List of the threads donating their priority to the thread which
owns this list. Each thread has its own list.

 - struct lock *lock_to_acquire

Lock the thread is waiting for (equals NULL if there's no lock to
wait for). Useful to determine when to donate and restore priority.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

A list of the priority donors will be used to track priority donation.
A thread is added to such a list as soon as its attribute lock_to_acquire
is not equal to NULL anymore. It then donates its priority to the thread
holding the lock so that it can be released.

If a nested donation situation occurs, the lock holder priority will
be updated using the thread->priority attribute. Unlike the thread->
original_priority which keeps a record of the thread's very own 
priority, thread->priority corresponds, when the donors list is not 
empty, to the highest donated priority. The following ASCII diagram
presents the evolution of the thread->priority attribute when a nested
donation occurs.

                       -- ASCII DIAGRAM -- 
A, B and C are three threads with a respective priority L (low), M
(medium) and H (high). C is waiting for a lock held by B, and B is 
also waiting for a lock held by A. According to priority scheduling,
C will be run first.
"x" represents a lock. "x Y" represents a lock held by thread Y.
". . ." represents an attempt to acquire a lock.
"---->" represents a priority donation.


                                Priority of A | B | C
C . . . x B                                 L | M | H
C ----> x B                                 L | H | H   
C ----> x B . . . x A                       L | H | H
C ----> x B ----> x A                       H | H | H

  ==> C's priority_donors list: empty || lock_to_acquire: B
  ==> B's priority_donors list: C     || lock_to_acquire: A
  ==> A's priority_donors list: B     || lock_to_acquire: NULL

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

A thread holding a lock/semaphore/condition variables that the highest
priority thread is waiting for will be donated the highest priority 
thread's priority in order to execute and release the lock. Once the 
lock has been release, the thread who held it will loose its donated
priority and return to a lower priority. The next thread to be run 
will be chosen on its priority: the highest priority thread will thus 
be the first to wake up.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

If a call to lock_acquire() causes a priority donation, it means that 
a thread A is trying to acquire a lock that is already held by a thread
B, which has a lower priority than thread A. 

In order to release the lock, A updates its lock_to_acquire attribute 
with the lock. A then adds itself to the priority_donors list of B.
If A->priority > B->priority (which can either be a donated priority if
the priority_donors list is not empty or equal to B->original_priority
if then priority_donors list is empty), then B->priority = A->priority, 
which will allow B to run and release its lock. 

(As previously mentioned in B2, the thread->priority attribute takes 
nested donation into account: the nested threads priority is updated 
"level by level", which implies that every time a thread is added to 
the nest, the priority attribute of its donors already corresponds to 
the donors' donated priority, and so on.)


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

(A and B are the threads used as example in question B4.)

If lock_release() is called, then lock->holder = NULL (before the call,
lock->holder = B). A is removed from B's priority_donors list. If B's 
priority_donors list is not empty, then B->priority = highest_priority
_thread->priority; if the list is empty, then B->priority = original_
priority. A acquires the lock (lock->holder = A) and is ready to run. 
To be cautious, we then check if the running thread B has a higher
priority than the threads in the ready_list. If it's not the case, 
we call thread_yield() to yield the processor.


---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A potential race would happen if the interrupt handler was modifying
the current thread's priority attribute while this priority attribute
was being updated to the new_priority (argument of the thread_set_
priority function). In order to avoid race conditions, we are 
disabling the interrupts while the current thread's priority is being
updated. A lock cannot be used to avoid this race because the interrupt 
handler - which would be at the origin of the race condition - cannot 
acquire a lock.

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

At the very beginning, we were thinking of sorting the ready_list because
it seemed easier to implement scheduling without donation this way. However,
it turned out that sorting the ready_list every single time it is modified
(which happens a lot) would be a waste of time and resources, especially
when the ready_list would contain a lot of threads. Moreover, it would not
really come in handy when implementing priority donation.

We thus decided to keep the ready_list unsorted, and simply use a get_highest
_priority() function that would return the thread with the highest t->priority
attribute. As we explained before, the priority attribute takes into account
nested donations and is updated "level by level" in the nest. The use of
original_priority allows us to keep the inital priority of a thread, which
means that a thread will never be deprived of priority, not even when its
priority_donators list will be empty. It also allows us to get the highest
priorities iteratively rather than using only a t->priority attribute and 
finding the highest priorities recursively: if we had a huge nest, recursion
could get more expensive than iteration, and we would need to go to the first
level in the nest every single time we would need to get the highest priority
instead of simply going to the upper level.

			  ADVANCED SCHEDULER
			    (If Attempted)
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0
 4
 8
12
16
20
24
28
32
36

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

We didn't attempt the third problem, but the assignment itself wasn't
especially hard. Implementing timer_sleep and the priority scheduling
is not really complicated; the hardest and longer part was trying to
understand the given code, and then figuring out what has to be modified.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

The priority scheduling part was really interesting and useful to properly
understand how scheduling works.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

///

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

///

>> Any other comments?

///
